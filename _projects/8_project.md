---
title: "LLM Testing" 
team: "Kausik Lakkaraju, Sara Rae Jones, Sai Krishna Revanth Vuruma, Vishal Pallagani, Bharath Muppasani, Biplav Srivastava"  
description: "Increasingly powerful Large Language Model (LLM) based chatbots, like ChatGPT and Bard, are becoming available to users that have the potential to revolutionize the quality of decision-making achieved by the public. We find that although the outputs of the chatbots are fluent and plausible, there are still critical gaps in providing accurate and reliable information using LLM-based chatbots. [More Details](https://ai4society.github.io/llm_pge/)"
# description: "Artificial Intelligence (AI) systems like facial recognition systems and sentiment 
# analyzers are known to exhibit model uncertainty which can be perceived as 
# algorithmic bias in most cases (esp. in the presence of protected attributes like 
# gender and race). This line of work aims to examine and, if possible, mitigate the 
# bias in AI systems by establishing causal relationships. Based on this, we would 
# assign a rating to the AI system, which helps the user make an informed selection 
# when choosing different systems for their application. [More Details](https://ai4society.github.io/rating_page/)"    
Relevant_Papers: "[2023-3](../papers#2022-3)"
---



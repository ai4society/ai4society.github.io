<!doctype html>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
    <title>Trustworthy Group Recommendation</title>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/all.min.css"></script>
    <link rel="stylesheet" type="text/css" href="./stylesheet.css" />
  </head>

  <body class="container">
    <!--JS functions-->
    <script>
      function setupModal(imageId, modalId, modalImgId, captionId, closeClass) {
        // Get the modal
        var modal = document.getElementById(modalId);

        // Get the image and insert it inside the modal - use its "alt" text as a caption
        var img = document.getElementById(imageId);
        var modalImg = document.getElementById(modalImgId);
        var captionText = document.getElementById(captionId);

        // Function to open the modal with the clicked image
        function openModal() {
          modal.style.display = "block";
          modalImg.src = this.src;
          captionText.innerHTML = this.alt;
        }

        // Function to close the modal
        function closeModal() {
          modal.style.display = "none";
        }

        // Set up event listener for image click
        img.onclick = openModal;

        // Get the <span> element that closes the modal
        var span = document.getElementsByClassName(closeClass)[0];

        // Set up event listener for span click
        span.onclick = closeModal;
      }
    </script>

    <table
      style="
        width: 80%;
        border: 0px;
        border-spacing: 0px;
        border-collapse: separate;
        margin-right: auto;
        margin-left: auto;
      "
    >
      <tbody>
        <!--AI4Society Home - link back to homepage-->
        <tr style="padding: 0px">
          <td style="padding-left: 2.5%; padding-top: 3%; width: 63%; vertical-align: middle">
            <p style="text-align: left"><a href="https://ai4society.github.io/">AI4Society Home</a> &nbsp/&nbsp</p>
          </td>
        </tr>

        <tr style="padding: 0px">
          <!--Page header and news-->
          <td style="padding-left: 2.5%; width: 63%; vertical-align: middle">
            <h1 style="display: flex; align-items: center">
              <span
                style="background-color: cyan; height: 20px; width: 20px; margin-right: 10px; border: 1px solid black"
              ></span>
              Trustworthy Group Recommendation
            </h1>

            <div
              style="
                border: 2px solid #59bcfe;
                border-radius: 5px;
                padding: 15px;
                background-color: #f3fffe;
                box-shadow: 2px 2px 8px rgba(59, 72, 255, 0.474);
                font-family: Arial, sans-serif;
              "
            >
              <h4 style="margin: 0 0 5px 0; color: #018b92">Key Idea</h4>
              <p style="margin: 0; font-size: 14.5px; line-height: 1.6; color: #333333">
                Our research in <strong>Trustworthy Group Recommendation</strong> focuses on developing fair,
                transparent, robust, and user-aligned algorithms that support effective <i>group</i> decision-making,
                with applications like <i>ULTRA</i> that quickly help form research teams and match them with relevant
                funding opportunities.
              </p>
            </div>
            <br />

            <div style="border: 3px solid black; padding: 10px; font-family: Arial, sans-serif">
              <p style="margin: 0 0 10px 0">
                <b>Quick Start</b>
              </p>
              <ol style="margin: 0; padding-left: 18px; font-size: 13.5px; color: #333; line-height: 1.6">
                <li>
                  See our latest work on BEACON <a href="http://3.144.8.247/" target="_blank">[demo]</a>, a personalized
                  meal planning system to assist with making optimized meal choices over a time period, incorporating
                  various food restrictions, chronic health conditions, regional cuisine preferences, as well as
                  balancing short- and long-term constraints to promote individual health and happines
                  <a href="https://arxiv.org/abs/2412.17910" target="_blank">[Paper]</a>
                  <a href="https://github.com/SCCapstone/beacon-of-hope" target="_blank"
                    >[Github - capstone prototype]</a
                  >
                </li>

                <li>
                  <img
                    id="myImg0"
                    src="images/ultra_award.jpeg"
                    alt="ðŸŽ‰ 2024 AAAI-IAAI Deployed Application Award for our AI application, <i>Promoting Research Collaboration with Open Data Driven Team Recommendation in Response to Call for Proposals</i> ðŸŽ‰"
                    style="width: 100%; max-width: 100px; height: 62px"
                  />
                  See our past work on ULTRA, a novel AI-based system for assisting team formation when researchers
                  respond to RFPs from funding agencies. It has been awarded the <i>Deployed Application Award</i> by
                  AAAI-IAAI 2024 <i>(can be enlarged on the right)</i> and featured in AI Magazine 2024:
                  <a
                    href="https://onlinelibrary.wiley.com/doi/pdf/10.1002/aaai.12203"
                    target="_blank"
                    style="color: #007acc; text-decoration: none"
                    >[Paper]</a
                  >
                  <a
                    href="http://casy.cse.sc.edu/ultra/teaming/"
                    target="_blank"
                    style="color: #007acc; text-decoration: none"
                    >[Demo Website]</a
                  >
                </li>
              </ol>
            </div>

            <div id="myModal" class="modal">
              <span class="close">&times;</span>
              <img class="modal-content" id="img01" />
              <div id="caption"></div>
            </div>

            <script>
              // Call the function with your specific IDs and class
              setupModal("myImg0", "myModal", "img01", "caption", "close");
            </script>

            <hr />

            <details open>
              <summary><b>Group Recommendation and Fairness</b></summary>
              <div class="content">
                <!--Group reco and fairness-->
                <p style="text-align: justify">
                  <i
                    ><b>Key Contacts: </b
                    ><a target="_blank" href="https://sites.google.com/site/biplavsrivastava/home?authuser=0"
                      >Biplav Srivastava</a
                    >, <a target="_blank" href="https://www.linkedin.com/in/likitha9/">Siva Likitha Valluru</a>,
                    <a
                      target="_blank"
                      href="https://sc.edu/study/colleges_schools/engineering_and_computing/faculty-staff/michaelhuhns.php"
                      >Michael Huhns</a
                    >,
                    <a target="_blank" href="https://personal.utdallas.edu/~sriraam.natarajan/">Sriraam Natarajan</a></i
                  >
                  <br />
                </p>
                <p align="justify">
                  <img
                    id="myImg1"
                    src="images/group_recommendation.jpg"
                    alt="Group Recommendation - Research Potential, Methods, and Fairness"
                    style="width: 100%; max-width: 100px; height: 120px"
                  />We study the problem of group recommendation, an information exploration paradigm that retrieves
                  interesting items for users based on their profiles and past interactions/activities/history. Existing
                  literature encourages using greedy methods, genetic and heuristic algorithms, topic diversification,
                  and cost constraint bi-objective optimizations. Our objective is to build novel methods and useful
                  tools for group recommendation with fairness, and drive different use cases (e.g., meal
                  recommendation). <br /><br />
                  <span style="color: violet"
                    ><i
                      >The underlying research directions and applications are summarized in the poster to the right
                      (can be enlarged).</i
                    ></span
                  >
                </p>

                <!-- The Modal -->
                <div id="myModal" class="modal">
                  <span class="close">&times;</span>
                  <img class="modal-content" id="img01" />
                  <div id="caption"></div>
                </div>

                <script>
                  // Call the function with your specific IDs and class
                  setupModal("myImg1", "myModal", "img01", "caption", "close");
                </script>
              </div>
            </details>

            <hr />

            <!--Team formation-->
            <details>
              <summary><b>Team Formation</b></summary>
              <div class="content">
                <p style="text-align: justify">
                  <i
                    ><b>Technical Lead: </b
                    ><a target="_blank" href="https://sites.google.com/site/biplavsrivastava/home?authuser=0"
                      >Biplav Srivastava</a
                    ></i
                  ><br />
                  <i
                    ><b>Collaborators over the years: </b>
                    <a target="_blank" href="https://www.linkedin.com/in/likitha9/">Siva Likitha Valluru</a>,
                    <a target="_blank" href="https://www.linkedin.com/in/sai-teja-paladi-52a062140/">Sai Teja Paladi</a
                    >, <a target="_blank" href="https://www.linkedin.com/in/m-xander-widener/">Michael Widener</a>,
                    Rohit Sharma,
                    <a target="_blank" href="https://www.linkedin.com/in/owen-bond-0a146a20b/">Owen Bond</a>,
                    <a target="_blank" href="https://www.researchgate.net/profile/Ronak_Shah9">Ronak Shah</a>,
                    <a target="_blank" href="https://www.linkedin.com/in/austin-hetherington-503a32203/"
                      >Austin Hetherington</a
                    > </i
                  ><br />
                  <i
                    ><b>External Collaborators: </b>
                    <a target="_blank" href="https://aniketgupta01.wordpress.com/">Aniket Gupta</a>,
                    <a target="_blank" href="https://dtrycode.github.io/">Siwen Yan</a>,
                    <a target="_blank" href="https://personal.utdallas.edu/~sriraam.natarajan/">Sriraam Natarajan</a>,
                    <a target="_blank" href="https://www.researchgate.net/profile/Tarmo-Koppel">Tarmo Koppel</a>,
                    <a target="_blank" href="https://www.iitr.ac.in/~CSE/Gangopadhyay_Sugata"
                      >Sugata Gangopadhyay</a
                    > </i
                  ><br />
                  <i
                    ><b>Advisors: </b
                    ><a
                      target="_blank"
                      href="https://sc.edu/study/colleges_schools/engineering_and_computing/faculty-staff/matthews.php"
                      >Michael Matthews</a
                    >,
                    <a
                      target="_blank"
                      href="https://sc.edu/study/colleges_schools/engineering_and_computing/faculty-staff/ziehl_paul.php"
                      >Paul Ziehl</a
                    >,
                    <a
                      target="_blank"
                      href="https://sc.edu/study/colleges_schools/engineering_and_computing/faculty-staff/michaelhuhns.php"
                      >Michael Huhns</a
                    >,
                    <a
                      target="_blank"
                      href="https://sc.edu/study/colleges_schools/engineering_and_computing/faculty-staff/mcelwain.php"
                      >Danielle McElwain</a
                    ></i
                  ><br />
                </p>

                <p align="justify">
                  <img
                    id="myImg2"
                    src="./images/ultra_poster.jpg"
                    alt="A poster of ULTRA."
                    style="width: 100%; max-width: 100px; height: 150px"
                  />We introduce
                  <span style="color: violet"
                    >ULTRA (<b><u>U</u></b
                    >niversity <b><u>L</u></b
                    >ead <b><u>T</u></b
                    >eam <b><u>B</u></b
                    >uilder from <b><u>R</u></b
                    >FPs and <b><u>A</u></b
                    >nalysis)</span
                  >, a novel AI-based system for assisting team formation when researchers respond to RFPs from funding
                  agencies. This is an instance of the general problem of building teams when demand opportunities come
                  periodically and potential members may vary over time. The novelties of our approach are that we: (a)
                  extract technical skills needed about researchers and calls from multiple <i>open</i> data sources and
                  normalize them using NLP techniques, (b) build teaming solutions based on constraints, (c)
                  computationally and qualitatively evaluate our system in two diverse settings (US, India) to establish
                  generality of our approach, and (d) create and publish a dataset that others can use.<br /><br />
                  <span style="color: violet"
                    ><i
                      >(This research study has been certified as exempt from the IRB per 45 CFR 46.104(d)(3) and 45 CFR
                      46.111(a)(7) by University of South Carolina IRB#Pro00127449.)</i
                    ></span
                  >
                </p>

                <script>
                  setupModal("myImg2", "myModal", "img01", "caption", "close");
                </script>

                <p>
                  <i><b>Representative Publications</b></i>
                </p>
                <ul style="padding-left: 2.5%; width: 100%; vertical-align: middle">
                  <li>
                    [2024] AI-Assisted Research Collaboration with Open Data for Fair and Effective Response to Call for
                    Proposals <br /><i>AAAI AI Magazine</i><br />
                    <a href="https://onlinelibrary.wiley.com/doi/full/10.1002/aaai.12203" target="_blank"
                      ><b>[Paper]</b></a
                    >
                    <br /><br />
                  </li>

                  <li>
                    <img
                      id="myImg0"
                      src="images/ultra_award.jpeg"
                      alt="ðŸŽ‰ 2024 AAAI-IAAI Deployed Application Award for our AI application, <i>Promoting Research Collaboration with Open Data Driven Team Recommendation in Response to Call for Proposals</i> ðŸŽ‰"
                      style="width: 100%; max-width: 100px; height: 60px"
                    />[2024] Promoting Research Collaboration with Open Data Driven Team Recommendation in Response to
                    Call for Proposals <b>[Awarded <i>Deployed Application Award</i> from AAAI-IAAI 2024]</b> <br /><i
                      >The Thirty-Sixth Annual Conference on Innovative Applications of Artificial Intelligence
                      (IAAI-24)</i
                    ><br />
                    <b
                      >[Tool Websites at <a href="http://casy.cse.sc.edu/ultra/teaming/" target="_blank">UofSC</a>,
                      <a href="http://casy.cse.sc.edu/ultra/iitr/" target="_blank">IIT-R</a>]</b
                    >
                    <b
                      >[Demo Videos for <a href="https://www.youtube.com/watch?v=8MUtxsfVNIU" target="_blank">UofSC</a>,
                      <a href="https://www.youtube.com/watch?v=CUk_Rgvd5kg" target="_blank">IIT-R</a>]</b
                    >
                    <a href="https://arxiv.org/abs/2309.09404" target="_blank"><b>[Paper]</b></a>
                    <a href="./bib/ultra-iaai.bib" target="_blank" type="text/plain"><b>[BibTex]</b></a>
                    <br /><br />
                    <div class="video-container" style="display: flex; justify-content: center">
                      <iframe
                        width="560"
                        height="315"
                        src="https://www.youtube.com/embed/8MUtxsfVNIU"
                        title="Demo of ULTRA Tool: Team Recommendation for Researchers for Responding to Calls for Proposals"
                        frameborder="0"
                        allow="
                          accelerometer;
                          autoplay;
                          clipboard-write;
                          encrypted-media;
                          gyroscope;
                          picture-in-picture;
                          web-share;
                        "
                        allowfullscreen
                      ></iframe>
                    </div>
                  </li>
                  <br />
                  <li>
                    [2024] ULTRA: Exploring Team Recommendations in Two Geographies Using Open Data in Response to Call
                    for Proposals. <br /><i
                      >ACM India Joint International Conference on Data Science and Management of Data
                      (CODS-COMAD-2024)</i
                    ><br />
                    <a href="https://dl.acm.org/doi/10.1145/3632410.3632503" target="_blank"><b>[Paper]</b></a>
                    <a href="./bib/ultra-cods.bib" target="_blank" type="text/plain"><b>[BibTex]</b></a>
                    <br /><br />
                  </li>
                  <li>
                    [2022] ULTRA: A Data-driven Approach for Recommending Team Formation in Response to Proposal Calls.
                    <br /><i>IEEE ICDM Workshop on AI for Nudging and Personalization (WAIN)</i><br />
                    <a href="https://arxiv.org/abs/2201.05646" target="_blank"><b>[Paper]</b></a>
                    <a href="./bib/ultra-icdm.bib" target="_blank" type="text/plain"><b>[BibTex]</b></a>
                    <br />
                  </li>
                  <br />

                  <center>
                    <div>
                      <figure class="imageLeft">
                        <img class="top" src="images/ultra_teaming_setup.png" width="330" height="250" />
                        <figcaption>Figure 1: Teaming setup of ULTRA.</figcaption>
                      </figure>
                      <figure class="imageRight">
                        <img class="average" src="images/ultra_system_architecture.png" width="330" height="250" />
                        <figcaption>Figure 2: System architecture of ULTRA.</figcaption>
                      </figure>
                    </div>
                  </center>
                </ul>

                <h3>
                  <span style="background-color: aqua"><b>Additional Tools</b></span>
                </h3>
                <i
                  ><b>Collaborators over the years: </b>
                  <a target="_blank" href="https://aniketgupta01.wordpress.com/">Aniket Gupta</a>,
                  <a target="_blank" href="https://sites.google.com/site/biplavsrivastava/home?authuser=0"
                    >Biplav Srivastava</a
                  >, Karan Aggarwal,
                  <a target="_blank" href="https://www.linkedin.com/in/sai-teja-paladi-52a062140/"
                    >Sai Teja Paladi</a
                  > </i
                ><br />

                <p align="justify">
                  Here, we describe some of the important tools that we have developed as part of the
                  <a
                    href="https://ai4society.github.io/teaming/#:~:text=can%20be%20enlarged).-,Team%20Formation,-Technical%20Lead%3A"
                    >ULTRA</a
                  >
                  effort. They started out as useful features that we then made into stand-alone capabilities
                  recognizing their potentia for wider usage:
                </p>
                <ul style="padding-left: 2.5%; width: 100%; vertical-align: middle">
                  <li>
                    <p align="justify">
                      <img
                        id="myImg3"
                        src="./images/kite.png"
                        alt="KITE - An Unsupervised, Effective and Inclusive Approach for Textual Content Exploration."
                        style="width: 100%; max-width: 100px; height: 48px"
                      /><span style="color: violet">KITE (right)</span> is an unsupervised system for exploring textual
                      data which can generate insights from a general as well as a domain-dependent perspective
                      consisting of holistic views, entity-centric view, events view, domain-specific interpretation
                      using industry taxonomies and a detailed full-text view transparently connecting the document to
                      insight elements.
                    </p>

                    <script>
                      setupModal("myImg3", "myModal", "img01", "caption", "close");
                    </script>
                  </li>
                  <li>
                    <p align="justify">
                      We also developed a <span style="color: violet"><i>text-to-classification mapper</i></span
                      >, a tool that takes the input as a text and matching threshold as a number and returns the
                      <a href="https://cran.r-project.org/web/classifications/ACM.html" target="_blank">ACM</a> or
                      <a href="https://cran.r-project.org/web/ classifications/JEL.html" target="_blank">JEL</a>
                      classification codes and description based on the input text.
                    </p>
                  </li>
                </ul>

                <p>
                  <i><b>Representative Publications</b></i>
                </p>
                <ul style="padding-left: 2.5%; width: 100%; vertical-align: middle">
                  <li>
                    [2022] KITE - An Unsupervised, Effective and Inclusive Approach for Textual Content Exploration.<br />
                    <a href="http://casy.cse.sc.edu/kite/" target="_blank"><b>[Tool Website]</b></a>
                    <!--<a href="https://clipchamp.com/watch/oPT2b3oHOAD" target="_blank"><b>[Demo Video]</b></a>-->
                    <a
                      href="https://www.researchgate.net/profile/Biplav-Srivastava/publication/363608853_KITE_-_An_Unsupervised_Effective_and_Inclusive_Approach_for_Textual_Content_Exploration/links/6324a33a071ea12e363a790e/KITE-An-Unsupervised-Effective-and-Inclusive-Approach-for-Textual-Content-Exploration.pdf"
                      target="_blank"
                      ><b>[Paper]</b></a
                    >
                    <a href="https://github.com/BunnyTeja/Text-Visualization" target="_blank"><b>[GitHub]</b></a>
                    <a href="./bib/kite.bib" target="_blank" type="text/plain"><b>[BibTex]</b></a>
                    <br /><br />
                    <!--<center>
                    <div style="position:relative;width:fit-content;height:fit-content;">
                      <a style="position:absolute;top:20px;right:1rem;opacity:0.8;"
                        href="https://clipchamp.com/watch/oPT2b3oHOAD?utm_source=embed&utm_medium=embed&utm_campaign=watch">
                        <img loading="lazy" style="height:22px;" src="https://clipchamp.com/e.svg"
                          alt="Made with Clipchamp" />
                      </a>
                      <iframe allow="autoplay;" allowfullscreen style="border:none"
                        src="https://clipchamp.com/watch/oPT2b3oHOAD/embed" width="560" height="315"></iframe>
                    </div>
                  </center>-->
                  </li>
                  <br />
                  <li>
                    [2022] A Text-to-Classification Mapper (Using ACM/JEL Subject Ontology Codes).<br />
                    <a href="http://casy.cse.sc.edu/mapper/" target="_blank"><b>[Tool Website]</b></a>
                    <br />
                    <center>
                      <img src="./images/ultra_mapper.png" width="560" height="315" /><br />
                      <figcaption>Figure 3: A demo of text-to-classification mapper.</figcaption>
                    </center>
                  </li>
                </ul>
              </div>
            </details>

            <hr />

            <!--Meal reco-->
            <details>
              <summary><b>Meal Recommendation</b></summary>
              <div class="content">
                <p style="text-align: justify"></p>
                <h3>
                  <span style="background-color: aqua"><b>Meal Recommendation</b></span>
                </h3>
                <br />
                <i>
                  <b>Key Contacts: </b>
                  <a target="_blank" href="https://vnagpal25.github.io/">Vansh Nagpal</a>,
                  <a target="_blank" href="https://kausik-l.github.io/">Kausik Lakkaraju</a>,
                  <a target="_blank" href="https://www.linkedin.com/in/likitha9/">Siva Likitha Valluru</a>,
                  <a target="_blank" href="https://sites.google.com/site/biplavsrivastava/about-biplav?authuser=0"
                    >Biplav Srivastava</a
                  > </i
                ><br />

                <div class="demo-box">
                  <h4>BEACON System - Now Available!</h4>
                  <p style="margin: 0; font-size: 14.5px">
                    We have developed <span class="highlight">BEACON</span> (Balancing Convenience and Nutrition), a
                    personalized meal planning system that helps people make optimized meal choices over time periods.
                    The system incorporates food restrictions, chronic health conditions, regional cuisine preferences,
                    and balances short- and long-term constraints to promote individual health and happiness.
                  </p>
                  <p style="margin: 10px 0 0 0">
                    <a href="http://3.144.8.247/" target="_blank"><b>[Live Demo]</b></a>
                    <a href="https://arxiv.org/abs/2412.17910" target="_blank"><b>[Paper]</b></a>
                    <a href="https://github.com/SCCapstone/beacon-of-hope" target="_blank"><b>[GitHub]</b></a>
                  </p>
                </div>

                <p align="justify">
                  Personal health can benefit significantly from meals planned over extended periods, whether for a
                  single day, a three-day travel period, or an entire week. Our research addresses this through
                  <span class="highlight">BEACON</span>, a data-driven meal recommender system designed to help both
                  healthy individuals and people with health conditions (such as diabetes) make optimized meal choices.
                </p>

                <p align="justify">The system leverages several innovative components:</p>

                <ul style="padding-left: 2.5%; width: 100%; vertical-align: middle">
                  <li>
                    <b>Variable Meal Configurations:</b> Users can customize meal structures (breakfast, lunch, dinner)
                    with different components (main course, side dishes, beverages, desserts)
                  </li>

                  <li>
                    <b>Flexible Time Horizons:</b> Recommendations span from single days up to multi-day periods,
                    enabling better long-term planning
                  </li>

                  <li>
                    <b>Rich Recipe Representation (R3):</b> Recipes are converted from text to a structured, multimodal
                    format that captures both content and preparation processes
                  </li>

                  <li>
                    <b>Advanced Recommendation Algorithms:</b> Using contextual bandits and reinforcement learning, the
                    system learns user preferences and provides highly personalized recommendations
                  </li>

                  <li>
                    <b>Comprehensive Goodness Metrics:</b> Evaluations consider duplicate avoidance, meal coverage, and
                    alignment with user dietary constraints
                  </li>

                  <li>
                    <b>Fairness Evaluation:</b> Ensures recommendations are unbiased and not stereotyped toward any
                    group of food items or user demographics
                  </li>
                </ul>

                <p align="justify">
                  The system has been deployed and tested with real users, demonstrating significant improvements over
                  baseline methods in balancing convenience with nutritional needs. BEACON represents a novel approach
                  to meal recommendation that moves beyond simple food suggestions to comprehensive meal planning with
                  health optimization.
                </p>

                <p>
                  <i><b>Representative Publications</b></i>
                </p>

                <ul style="padding-left: 2.5%; width: 100%; vertical-align: middle">
                  <li>
                    [2025] A Novel Approach to Balance Convenience and Nutrition in Meals With Long-Term Group
                    Recommendations and Reasoning on Multimodal Recipes and its Implementation in BEACON<br />
                    Presented at <i>WAIN workshop at IEEE ICDM 2025</i><br />
                    <a href="https://arxiv.org/abs/2412.17910" target="_blank"><b>[Paper]</b></a>
                    <a href="http://3.144.8.247/" target="_blank"><b>[Demo]</b></a>
                    <a href="https://github.com/SCCapstone/beacon-of-hope" target="_blank"><b>[GitHub]</b></a>
                    <br />
                  </li>
                  <li>
                    <img
                      id="myImg1"
                      src="images/Recipe-Translation-Picture.jpg"
                      alt="Recipe Translation"
                      style="width: 100%; max-width: 100px; height: 120px"
                    />[2025] An empirical study on the use of Large Language Models (LLMs) to translate recipes into a
                    semi-structured data format <br />
                    <i>Conference Poster at the National Big Data and Health Science Conference</i><br />
                    <a href="./bib/Recipe-Translation-Poster.pdf" target="_blank" type="text/plain"><b>[Poster]</b></a>
                  </li>
                  <br />
                  <br />
                  <li>
                    [2024] A Novel Approach to Balance Convenience and Nutrition in Meals With Long-Term Group
                    Recommendations and Reasoning on Multimodal Recipes and its Implementation in BEACON<br />
                    Presented at <i>National Big Data and Health Science Conference 2025</i><br />
                    as
                    <i
                      >A Digital Twin for Increasing Adherence to Dietary Guidelines with Personalized, AI-Driven, Long
                      Duration Meal Recommendations.</i
                    >
                    <a href="https://arxiv.org/abs/2412.17910" target="_blank"><b>[Paper]</b></a>
                    <a href="./bib/beacon-part2.bib" target="_blank" type="text/plain"><b>[BibTex]</b></a>
                    <br />
                  </li>
                  <li>
                    [2024] BEACON: Balancing Convenience and Nutrition in Meals With Long-Term Group Recommendations and
                    Reasoning on Multimodal Recipes<br />
                    <i>Arxiv Preprint</i><br />
                    <a href="https://arxiv.org/abs/2406.13714" target="_blank"><b>[Paper]</b></a>
                    <a href="./bib/beacon.bib" target="_blank" type="text/plain"><b>[BibTex]</b></a>
                    <br />
                  </li>
                  <br />
                </ul>
              </div>

              <div class="content">
                <p style="text-align: justify"></p>
                <h3>
                  <span style="background-color: aqua"><b>Recipe Recommendation</b></span>
                </h3>
                <br />
                <i
                  ><b>Collaborators over the years: </b>
                  <a target="_blank" href="https://vishalpallagani.github.io/">Vishal Pallagani</a>,
                  <a target="_blank" href="https://www.linkedin.com/in/khvedant/">Vedant Khandelwal</a>,
                  <a target="_blank" href="https://kausik-l.github.io/">Kausik Lakkaraju</a>,
                  <a target="_blank" href="https://www.revathycv.com/">Revathy Venkataramanan</a>,
                  <a target="_blank" href="https://sites.google.com/site/biplavsrivastava/about-biplav?authuser=0"
                    >Biplav Srivastava</a
                  > </i
                ><br />
                <i
                  ><b>External Collaborators: </b> Priyadharsini Ramamurthy,
                  <a target="_blank" href="https://hem-chandra.github.io/">Hem Chandra Joshi</a>,
                  <a target="_blank" href="https://saakur.github.io/">Sathyanarayanan N. Aakur</a>,
                  <a target="_blank" href="https://iitr.ac.in/~HS/Ram_Manohar_Singh">Ram Manohar Singh</a> </i
                ><br />

                <p align="justify">
                  Cooking domain is a popular use-case to demonstrate decision-support (AI) capabilities in service of
                  benefits like precision health with tools ranging from information retrieval interfaces to
                  task-oriented chatbots. The recipes today are handled as textual documents which makes it difficult
                  for machines to read, reason and handle ambiguity. This demands a need for better representation of
                  the recipes, overcoming the ambiguity and sparseness that exists in the current textual documents. We
                  constructed a machine-understandable
                  <span style="color: violet">rich recipe representation (R3)</span>, in the form of plans, from the
                  recipes available in natural language. R3 is infused with additional knowledge such as information
                  about allergens and images of ingredients, possible failures and tips for each atomic cooking step.

                  <br /><br />
                  To show the benefits of R3, we also built <span style="color: violet">TREAT</span>, a tool for recipe
                  retrieval which uses R3 to perform multi-modal reasoning on the recipe's content (plan objects -
                  ingredients and cooking tools), food preparation process (plan actions and time), and media type
                  (image, text). R3 leads to improved retrieval efficiency and new capabilities that were hither-to not
                  possible in textual representation.
                </p>

                <!--<script>
                // Get the modal
                var modal = document.getElementById("myModal");

                // Get the image and insert it inside the modal - use its "alt" text as a caption
                var img = document.getElementById("myImg2");
                var modalImg = document.getElementById("img01");
                var captionText = document.getElementById("caption");
                img.onclick = function () {
                  modal.style.display = "block";
                  modalImg.src = this.src;
                  captionText.innerHTML = this.alt;
                }

                // Get the <span> element that closes the modal
                var span = document.getElementsByClassName("close")[0];

                // When the user clicks on <span> (x), close the modal
                span.onclick = function () {
                  modal.style.display = "none";
                }
              </script>-->

                <p>
                  <i><b>Representative Publications</b></i>
                </p>
                <ul style="padding-left: 2.5%; width: 100%; vertical-align: middle">
                  <li>
                    [2022] A Rich Recipe Representation as Plan to Support Expressive Multi-Modal Queries on Recipe
                    Content and Preparation Process <br /><i
                      >Workshop on Knowledge Engineering for Planning and Scheduling (KEPS), International Conference on
                      Automated Planning and Scheduling (ICAPS)</i
                    ><br />
                    <a href="https://arxiv.org/abs/2203.17109" target="_blank"><b>[Paper]</b></a>
                    <a href="./bib/r3.bib" target="_blank" type="text/plain"><b>[BibTex]</b></a>
                    <center>
                      <img src="images/r3.png" width="560" height="280" /><br />
                      <figcaption>
                        Figure 4: Difference between textual representation and R3 for a single instruction.
                        <br /><br />
                        <br />
                        <li>
                          [2022] A Multi-Modal Decision Support System with Allergy-Aware Recipe Understanding Powered
                          by a Plan Representation <br />
                          <a
                            href="https://www.researchgate.net/publication/377721769_A_Multi-Modal_Decision_Support_System_with_Allergy-Aware_Recipe_Understanding_Powered_by_a_Plan_Representation"
                            target="_blank"
                            ><b>[Paper]</b></a
                          >
                          <a href="./bib/treat.bib" target="_blank" type="text/plain"><b>[BibTex]</b></a>
                          <br />
                          <center>
                            <img src="images/treat.png" width="560" height="280" /><br />
                            <figcaption>Figure 5: Result of user query of asking recipes containing bacon.</figcaption>
                          </center>
                        </li>
                        <br />

                        <hr />

                        <tr style="padding: 0px">
                          <td style="padding-left: 2.5%; width: 63%; vertical-align: middle">
                            <hr style="width: 100%; float: left" />
                          </td>
                        </tr>
                      </figcaption>
                    </center>
                  </li>
                </ul>
              </div>
            </details>
          </td>
        </tr>
      </tbody>
    </table>
  </body>
</html>

<!DOCTYPE HTML>
<html lang="en">

<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>LLM and Chatbot Testing</title>

    <meta name="viewport" content="width=device-width, initial-scale=1">

    <link rel="stylesheet" type="text/css" href="stylesheet.css">
</head>

<body class="container">

  <h2 style="display:flex;align-items:center;">
    <span style="background-color:hsl(37, 100%, 50%);height:20px;width:20px;margin-right:10px;border:1px solid black;"></span>
    LLM and Chatbot Testing
  </h2>
    <table style="width:80%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
        <tbody>
            <tr style="padding:0px">
                <td style="padding-left:2.5%;padding-top:3%;width:63%;vertical-align:middle">
                  <p style="text-align:left">
                    <a href='https://ai4society.github.io/'>Home</a>
                  </p>
                </td>
              </tr>

              <tr style="padding:0px">
                <td style="padding-left:2.5%;width:63%;vertical-align:middle">   


                  <p style="text-align: justify;"><span style="background-color: hsl(37, 100%, 70%);"><b>Evaluating Chatbots to Promote Users' Trust -- Practices and Open Problems
                  </b></span><br>
                  

                  <p style="text-align: justify;"><span style="background-color: hsl(37, 100%, 70%);"><b></b></span><br>
                      <i><b>Collaborators: </b>AIISC - University of South Carolina, Tallinn University of Technology, Cisco Research, IBM Research</i>
                      <br>
                      <i><b>Authors: </b>Biplav Srivastava, Kausik Lakkaraju, Tarmo Koppel, Vignesh Narayanan, Ashish Kundu, Sachindra Joshi</i>
                      <br>
                    </p>
                    <p style="text-align: justify;">
                      Chatbots, the common moniker for collaborative assistants, are Artificial Intelligence (AI) software that enables people to naturally interact with them to get tasks done. 
                      Although chatbots have been studied since the dawn of AI, they have particularly caught the imagination of the public and businesses since the launch of easy-to-use and general-purpose Large Language Model-based chatbots like ChatGPT. 
                      As businesses look towards chatbots as a potential technology to engage users, who may be end customers, suppliers, or even their own employees, proper testing of chatbots is important to address and mitigate issues of trust related to service or product performance, user satisfaction and long-term unintended consequences for society. 
                      This paper reviews current practices for chatbot testing, identifies gaps as open problems in pursuit of user trust, and outlines a path forward.
                    </p>
                  
                  <p><i><b>Representative Publications</b></i></p>
                  <ul>
                    <li>Evaluating Chatbots to Promote Users' Trust -- Practices and Open Problems
                      <br> <a href="https://arxiv.org/pdf/2309.05680.pdf" target="_blank"><b>[Paper]</b></a>
                      <!-- <a href="https://github.com/ai4society/LLM-CaseStudies/tree/main/Finance" target="_blank" type="text/plain"><b>[GitHub Respository]</b></a> -->
                      <a href="../llm_page/bib/chatbot_evaluation2023.txt" target="_blank" type="text/plain"><b>[BibTex]</b></a>
                    </li>
                  </ul>
                  <tr style="padding:0px">
                    <td style="padding-left:2.5%;width:73%;vertical-align:middle">
                        <img src="images/gpt.png" style="max-width:43%; display: block; margin: 0 auto;">
                    </td>
                  </tr>
                <!-- <tr style="padding:0px">
                <td style="padding-left:2.5%;width:63%;vertical-align:middle">
                  <img src="images/bard-q11.png" style="max-width:50%; display: block; margin: 0 auto;">
                </td>
              </tr>
              </td> 
            </tr>
            <br><br> -->


              <tr style="padding:0px">
                <td style="padding-left:2.5%;width:63%;vertical-align:middle">   


                  <p style="text-align: justify;"><span style="background-color: hsl(37, 100%, 70%);"><b>LLMs for Financial Advisement: A Fairness and Efficacy Study in Personal Decision Making</b></span><br>
                  

                  <p style="text-align: justify;"><span style="background-color: hsl(37, 100%, 70%);"><b></b></span><br>
                      <i><b>Collaborators: </b>AIISC, Department of Computer Science and Engineering - University of South Carolina</i>
                      <br>
                      <i><b>Authors: </b>Kausik Lakkaraju, Sara Elizabeth Jonees, Sai Krishna Revanth Vuruma, Vishal Pallagani, Bharath Muppasani, Biplav Srivastava</i>
                      <br>
                    </p>
                    <p style="text-align: justify;">
                      As Large Language Model (LLM) based chatbots are becoming more accessible, users are relying on these chatbots for reliable and personalized recommendations in diverse domains, ranging from code generation to financial advisement. In this context, we set out to investigate how such systems perform in the personal finance domain, where financial inclusion has been an overarching stated aim of banks for decades. We test widely used LLM-based chatbots, ChatGPT and Bard, and compare their performance against SafeFinance, a rule-based chatbot built using the Rasa platform.
                      The comparison is across two critical tasks: product discovery and multi-product interaction, where product refers to banking products like Credit Cards, Certificate of Deposits, and Checking Accounts.
                      With this study, we provide interesting insights into the chatbots' efficacy in financial advisement and their ability to provide fair treatment across different user groups. We find that both Bard and ChatGPT can make errors in retrieving basic online information, the responses they generate are inconsistent across different user groups, and they cannot be relied on for reasoning involving banking products.  
                      On the other hand, despite their limited generalization capabilities, rule-based chatbots like SafeFinance provide safe and reliable answers to users that can be traced back to their original source. Overall, although the outputs of the LLM-based chatbots are fluent and plausible, there are still critical gaps in providing consistent and reliable financial information.
                    </p>
                  
                  <p><i><b>Representative Publications</b></i></p>
                  <ul>
                    <li>LLMs for Financial Advisement: A Fairness and Efficacy Study in Personal Decision Making
                      <br> <a href="https://github.com/ai4society/LLM-CaseStudies/blob/main/Finance/paper/ICAIF_CameraReady2023.pdf" target="_blank"><b>[Paper]</b></a>
                      <a href="https://github.com/ai4society/LLM-CaseStudies/tree/main/Finance" target="_blank" type="text/plain"><b>[GitHub Respository]</b></a>
                      <a href="../llm_page/bib/icaif2023.txt" target="_blank" type="text/plain"><b>[BibTex]</b></a>
                    </li>
                  </ul>

            <br><br>

              <tr style="padding:0px">
                <td style="padding-left:2.5%;width:63%;vertical-align:middle">   


                  <p style="text-align: justify;"><span style="background-color: hsl(37, 100%, 70%);"><b>Can LLMs be Good Financial Advisors?: An Initial Study in Personal Decision
                    Making for Optimized Outcomes</b></span><br>
                  

                  <p style="text-align: justify;"><span style="background-color: hsl(37, 100%, 70%);"><b></b></span><br>
                      <i><b>Collaborators: </b>AIISC, Department of Computer Science and Engineering - University of South Carolina</i>
                      <br>
                      <i><b>Authors: </b>Kausik Lakkaraju, Sai Krishna Revanth Vuruma, Vishal Pallagani, Bharath Muppasani, Biplav Srivastava</i>
                      <br>
                    </p>
                    <p style="text-align: justify;">
                      Increasingly powerful Large Language Model (LLM) based chatbots, like ChatGPT and Bard, are becoming available to users that have the potential to revolutionize the quality of decision-making achieved by the public. 
                      In this context, we set out to investigate how such systems perform in the personal finance domain, where financial inclusion has been an overarching stated aim of banks for decades. 
                      We asked 13 questions representing banking products in personal finance: bank account, credit card, and certificate of deposits and their inter-product interactions, and decisions related to high-value purchases, payment of bank dues, and investment advice, and in different dialects and languages (English, African American Vernacular English, and Telugu). 
                      We find that although the outputs of the chatbots are fluent and plausible, there are still critical gaps in providing accurate and reliable financial information using LLM-based chatbots.
                    </p>
                  
                  <p><i><b>Representative Publications</b></i></p>
                  <ul>
                    <li>Can LLMs be Good Financial Advisors?: An Initial Study in Personal Decision Making for Optimized Outcomes
                      <br> <a href="https://arxiv.org/abs/2307.07422" target="_blank"><b>[Paper]</b></a>
                      <a href="../llm_page/bib/icaps_finplan2023.txt" target="_blank" type="text/plain"><b>[BibTex]</b></a>
                    </li>
                  </ul>
                  <tr style="padding:0px">
                    <td style="padding-left:2.5%;width:63%;vertical-align:middle">
                        <img src="images/diffs.png" style="max-width:43%; display: block; margin: 0 auto;">
                    </td>
                  </tr>
              </td> 

            </tr>
            <br><br>

        </tbody>
    </table>
    <script type="text/javascript" src="../js/script.js"></script>
</body>
</html>
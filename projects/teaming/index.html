<!DOCTYPE HTML>
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>Trustworthy Group Recommendation</title>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/all.min.css">
  </script>
  <link rel="stylesheet" type="text/css" href="./stylesheet.css">
</head>

<body class="container">

  <!--JS functions-->
  <script>
    function setupModal(imageId, modalId, modalImgId, captionId, closeClass) {
      // Get the modal
      var modal = document.getElementById(modalId);

      // Get the image and insert it inside the modal - use its "alt" text as a caption
      var img = document.getElementById(imageId);
      var modalImg = document.getElementById(modalImgId);
      var captionText = document.getElementById(captionId);

      // Function to open the modal with the clicked image
      function openModal() {
        modal.style.display = "block";
        modalImg.src = this.src;
        captionText.innerHTML = this.alt;
      }

      // Function to close the modal
      function closeModal() {
        modal.style.display = "none";
      }

      // Set up event listener for image click
      img.onclick = openModal;

      // Get the <span> element that closes the modal
      var span = document.getElementsByClassName(closeClass)[0];

      // Set up event listener for span click
      span.onclick = closeModal;
    }
  </script>



  <table style="width:80%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <!--AI4Society Home - link back to homepage-->
      <tr style="padding:0px">
        <td style="padding-left:2.5%;padding-top:3%;width:63%;vertical-align:middle">
          <p style="text-align:left">
            <a href='https://ai4society.github.io/'>AI4Society Home</a> &nbsp/&nbsp
          </p>
        </td>
      </tr>

      <tr style="padding:0px">

        <!--Page header and news-->
        <td style="padding-left:2.5%;width:63%;vertical-align:middle">
          <h1 style="display:flex;align-items:center;">
            <span
              style="background-color: cyan ;height:20px;width:20px;margin-right:10px;border:1px solid black;"></span>
            Trustworthy Group Recommendation
          </h1>
          <p style="border-width:3px; border-style:solid; border-color:black;padding: 10px;"><mark
              style="color:red;"><b>NEW!</b></mark> Our <a href="https://arxiv.org/abs/2309.09404">paper</a>
            that presents a novel system to recommend teams using a variety of AI methods has been accepted to <a
              href="https://aaai.org/aaai-conference/iaai-24-call-for-participation/"
              style="text-decoration:none;"><b><i>IAAI-AAAI'2024</i></b></a> and will receive the <span
              style="color:violet"><i>Innovative
                Application</i></span> award.</p>
          <p style="border-width:3px; border-style:solid; border-color:black;padding: 10px;"><mark
              style="color:red;"><b>NEW!</b></mark> Our <a href="https://dl.acm.org/doi/10.1145/3632410.3632503">demo
              paper</a> about deploying <a
              href="https://ai4society.github.io/projects/teaming/index.html#:~:text=We%20introduce%20ULTRA,others%20can%20use.">ULTRA</a>
            in two geographical regions of the world has been accepted to <a
              href="https://cods-comad.in/call-for-demo-track-papers.php"
              style="text-decoration:none;"><b><i>CODS-COMAD'2024</i></b></a>.</p>
          <hr>

          <details open>
            <summary><b>Group Recommendation and Fairness</b></summary>
            <div class="content">
              <!--Group reco and fairness-->
              <p style="text-align: justify;">
                <i><b>Authors: </b><a target="_blank"
                    href="https://sites.google.com/site/biplavsrivastava/home?authuser=0">Biplav Srivastava</a>, <a
                    target="_blank" href="https://www.linkedin.com/in/likitha9/">Siva Likitha Valluru</a>, <a
                    target="_blank"
                    href="https://sc.edu/study/colleges_schools/engineering_and_computing/faculty-staff/michaelhuhns.php">Michael
                    Huhns</a>, <a target="_blank" href="https://personal.utdallas.edu/~sriraam.natarajan/">Sriraam
                    Natarajan</a></i>
                <br>
              </p>
              <p align="justify"><img id="myImg" src="images/group_recommendation.jpg"
                  alt="Group Recommendation - Research Potential, Methods, and Fairness"
                  style="width:100%;max-width:100px;height:120px;">We study the problem of group recommendation, an
                information exploration
                paradigm that retrieves interesting items for users based on their profiles and past
                interactions/activities/history. Existing literature encourages using greedy methods, genetic and
                heuristic
                algorithms, topic diversification, and cost constraint bi-objective optimizations. Our objective is to
                build
                novel methods and useful tools for group recommendation with fairness, and drive different use cases
                (e.g.,
                meal recommendation). <br><br>
                <span style="color:violet"><i>The underlying research directions and applications are summarized in the
                    poster to the right (can be enlarged).</i></span>
              </p>

              <!-- The Modal -->
              <div id="myModal" class="modal">
                <span class="close">&times;</span>
                <img class="modal-content" id="img01">
                <div id="caption"></div>
              </div>

            <center>
              <div>
                <figure class="imageLeft">
                  <img class="top" src="images/ultra_teaming_setup.png" width="360" height="250" />
                  <figcaption> Figure 1: Teaming setup of ULTRA.</figcaption>
                </figure>
                <figure class="imageRight">
                  <img class="average" src="images/ultra_system_architecture.png" width="360" height="250" />
                  <figcaption> Figure 2: System architecture of ULTRA.</figcaption>
                </figure>
              </div>
            </center>

          </ul>




          <p style="text-align: justify;">
            <h3><span style="background-color: aqua;"><b>Recipe Recommendation</b></span></h3>
            <i><b>Collaborators over the years: </b>
              <a target="_blank" href="https://vishalpallagani.github.io/">Vishal Pallagani</a>,
              Vedant Khandelwal,
              <a target="_blank" href="https://kausik-l.github.io/">Kausik Lakkaraju</a>, 
              <a target="_blank" href="https://www.revathycv.com/">Revathy Venkataramanan</a>,
              <a target="_blank" href="https://sites.google.com/site/biplavsrivastava/about-biplav?authuser=0">Biplav Srivastava</a>
            </i><br>
            <i><b>External Collaborators: </b>
              <a target="_blank" href="https://saakur.github.io/">Sathyanarayanan N. Aakur</a>,
              Priyadharsini Ramamurthy 
            </i><br>
  

            <p align="justify"> Cooking domain is a popular use-case to demonstrate decision-support (AI) capabilities in service of benefits 
              like precision health with tools ranging from information retrieval interfaces to task-oriented chatbots. 
              The recipes today are handled as textual documents which makes it difficult for machines to read, reason and handle ambiguity. 
              This demands a need for better representation of the recipes, overcoming the ambiguity and sparseness that exists in the current textual documents. 
              We constructed a machine-understandable rich recipe representation (R3), in the form of plans, from the recipes available in natural language. 
              R3 is infused with additional knowledge such as information about allergens and images of ingredients, possible failures and tips for each atomic cooking step. 
              To show the benefits of R3, we also built TREAT, a tool for recipe retrieval which uses R3 to perform multi-modal reasoning on the recipe's content 
              (plan objects - ingredients and cooking tools), food preparation process (plan actions and time), and media type (image, text). 
              R3 leads to improved retrieval efficiency and new capabilities that were hither-to not possible in textual representation.</span>
          </p>
  
            <script>
              // Get the modal
              var modal = document.getElementById("myModal");
  
              // Get the image and insert it inside the modal - use its "alt" text as a caption
              var img = document.getElementById("myImg2");
              var modalImg = document.getElementById("img01");
              var captionText = document.getElementById("caption");
              img.onclick = function () {
                modal.style.display = "block";
                modalImg.src = this.src;
                captionText.innerHTML = this.alt;
              }
  
              // Get the <span> element that closes the modal
              var span = document.getElementsByClassName("close")[0];
  
              // When the user clicks on <span> (x), close the modal
              span.onclick = function () {
                modal.style.display = "none";
              }
            </script>
  

  
            <p><i><b>Representative Publications</b></i></p>
            <ul style="padding-left:2.5%;width:100%;vertical-align:middle">
              <li>[2022] A Rich Recipe Representation as Plan to Support Expressive Multi-Modal Queries
                on Recipe Content and Preparation Process
                <br><i>2022 Workshop on Knowledge Engineering for Planning and Scheduling</i><br>
                <a href="https://arxiv.org/abs/2203.17109" target="_blank"><b>[Paper]</b></a>
                <a href="./bib/r3.bib" target="_blank" type="text/plain"><b>[BibTex]</b></a>
                <br><br>
              </li>
              <br>
              <li>[2022] A Multi-Modal Decision Support System with Allergy-Aware Recipe Understanding Powered by a Plan Representation
                <!-- <a href="https://arxiv.org/abs/2201.05646" target="_blank"><b>[Paper]</b></a> -->
                <a href="./bib/treat.bib" target="_blank" type="text/plain"><b>[BibTex]</b></a>
                <br>
              </li>
              <br>
  
              <center>
                <div>
                  <figure class="imageLeft">
                    <img class="top" src="images/r3.png" width="480" height="320" />
                    <figcaption> Figure 3: Difference between textual representation and R3 for a single instruction.</figcaption>
                  </figure>
                  <figure class="imageRight">
                    <img class="average" src="images/treat.png" width="480" height="250" />
                    <figcaption> Figure 4: Result of user query of asking recipes containing
                      bacon.</figcaption>
                  </figure>
                </div>
              </center>
  
            </ul>
  




          <h3><span style="background-color: aqua;"><b>Additional Tools</b></span></h3>
          <i><b>Collaborators over the years: </b>
            <a target="_blank" href="https://aniketgupta01.wordpress.com/">Aniket Gupta</a>,
            <a target="_blank" href="https://sites.google.com/site/biplavsrivastava/home?authuser=0">Biplav
              Srivastava</a>,
            Karan Aggarwal, <a target="_blank" href="https://www.linkedin.com/in/sai-teja-paladi-52a062140/">Sai Teja
              Paladi</a>
          </i><br>

          <p align="justify">Here, we describe some of the important tools that we have developed as part of the <a
              href="https://ai4society.github.io/teaming/#:~:text=can%20be%20enlarged).-,Team%20Formation,-Technical%20Lead%3A">ULTRA</a>
            effort. They started out as useful features that we then made into stand-alone capabilities recognizing
            their potentia for wider usage:</p>
          <ul style="padding-left:2.5%;width:100%;vertical-align:middle">
            <li>
              <p align="justify"><img id="myImg3" src="./images/kite.png"
                  alt="KITE - An Unsupervised, Effective and Inclusive Approach for Textual Content Exploration."
                  style="width:100%;max-width:100px;height:48px;"><span style="color:violet">KITE (right)</span> is an
                unsupervised system for exploring textual
                data which can generate insights from a general as well as a domain-dependent perspective consisting of
                holistic views, entity-centric view, events view, domain-specific interpretation using industry
                taxonomies and a detailed full-text view transparently connecting the document to insight elements.</p>
              <script>
                // Call the function with your specific IDs and class
                setupModal("myImg", "myModal", "img01", "caption", "close");
              </script>
            </div>
          </details>

          <hr>

          <!--Team formation-->
          <details>
            <summary><b>Team Formation</b></summary>
            <div class="content">
              <p style="text-align: justify;">
                <i><b>Technical Lead: </b><a target="_blank"
                    href="https://sites.google.com/site/biplavsrivastava/home?authuser=0">Biplav Srivastava</a></i><br>
                <i><b>Collaborators over the years: </b>
                  <a target="_blank" href="https://www.linkedin.com/in/likitha9/">Siva Likitha Valluru</a>,
                  <a target="_blank" href="https://www.linkedin.com/in/sai-teja-paladi-52a062140/">Sai Teja Paladi</a>,
                  <a target="_blank" href="https://www.linkedin.com/in/m-xander-widener/">Michael Widener</a>, Rohit
                  Sharma,
                  <a target="_blank" href="https://www.linkedin.com/in/owen-bond-0a146a20b/">Owen Bond</a>,
                  <a target="_blank" href="https://www.researchgate.net/profile/Ronak_Shah9">Ronak Shah</a>,
                  <a target="_blank" href="https://www.linkedin.com/in/austin-hetherington-503a32203/">Austin
                    Hetherington</a>
                </i><br>
                <i><b>External Collaborators: </b>
                  <a target="_blank" href="https://aniketgupta01.wordpress.com/">Aniket Gupta</a>,
                  <a target="_blank" href="https://dtrycode.github.io/">Siwen Yan</a>,
                  <a target="_blank" href="https://personal.utdallas.edu/~sriraam.natarajan/">Sriraam Natarajan</a>,
                  <a target="_blank" href="https://www.researchgate.net/profile/Tarmo-Koppel">Tarmo Koppel</a>,
                  <a target="_blank" href="https://www.iitr.ac.in/~CSE/Gangopadhyay_Sugata">Sugata Gangopadhyay</a>
                </i><br>
                <i><b>Advisors: </b><a target="_blank"
                    href="https://sc.edu/study/colleges_schools/engineering_and_computing/faculty-staff/matthews.php">Michael
                    Matthews</a>, <a target="_blank"
                    href="https://sc.edu/study/colleges_schools/engineering_and_computing/faculty-staff/ziehl_paul.php">Paul
                    Ziehl</a>, <a target="_blank"
                    href="https://sc.edu/study/colleges_schools/engineering_and_computing/faculty-staff/michaelhuhns.php">Michael
                    Huhns</a>, <a target="_blank"
                    href="https://sc.edu/study/colleges_schools/engineering_and_computing/faculty-staff/mcelwain.php">Danielle
                    McElwain</a></i><br>

              <p align="justify"><img id="myImg2" src="./images/ultra_poster.jpg" alt="A poster of ULTRA."
                  style="width:100%;max-width:100px;height:150px;">We introduce ULTRA (<b><u>U</u></b>niversity
                <b><u>L</u></b>ead <b><u>T</u></b>eam
                <b><u>B</u></b>uilder from <b><u>R</u></b>FPs and <b><u>A</u></b>nalysis), an novel AI-based system for
                assisting team formation when researchers respond to RFPs from funding agencies. This is an instance of
                the
                general problem of building teams when demand opportunities come periodically and potential members may
                vary
                over time. The novelties of our approach are that we: (a) extract technical skills needed about
                researchers
                and calls from multiple <i>open</i> data sources and normalize them using NLP techniques, (b) build
                teaming
                solutions based on constraints, (c) computationally and qualitatively evaluate our system in two diverse
                settings (US, India) to establish generality of our approach, and (d) create and publish a dataset that
                others can use.<br><br> <span style="color:violet"><i>(This research study has been certified as exempt
                    from
                    the IRB per 45 CFR 46.104(d)(3) and 45 CFR 46.111(a)(7) by University of South Carolina
                    IRB#Pro00127449.)</i></span>
              </p>

              <script>
                setupModal("myImg2", "myModal", "img01", "caption", "close");
              </script>

              <p><i><b>Representative Publications</b></i></p>
              <ul style="padding-left:2.5%;width:100%;vertical-align:middle">
                <li>[2024] Promoting Research Collaboration with Open Data Driven Team Recommendation in Response to
                  Call
                  for Proposals
                  <br><i>The Thirty-Sixth Annual Conference on Innovative Applications of Artificial Intelligence
                    (IAAI-24)</i><br>
                  <b>[Tool Websites at <a href="http://casy.cse.sc.edu/ultra/teaming/" target="_blank">UofSC</a>, <a
                      href="http://casy.cse.sc.edu/ultra/iitr/" target="_blank">IIT-R</a>]</b>
                  <b>[Demo Videos for <a href="https://www.youtube.com/watch?v=8MUtxsfVNIU" target="_blank">UofSC</a>,
                    <a href="https://www.youtube.com/watch?v=CUk_Rgvd5kg" target="_blank">IIT-R</a>]</b>
                  <a href="https://arxiv.org/abs/2309.09404" target="_blank"><b>[Paper]</b></a>
                  <a href="./bib/ultra-iaai.bib" target="_blank" type="text/plain"><b>[BibTex]</b></a>
                  <br><br>
                  <div class="video-container" style="display: flex; justify-content: center;">
                    <iframe width="560" height="315" src="https://www.youtube.com/embed/8MUtxsfVNIU"
                      title="Demo of ULTRA Tool: Team Recommendation for Researchers for Responding to Calls for Proposals"
                      frameborder="0"
                      allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
                      allowfullscreen></iframe>
                  </div>
                </li>
                <br>
                <li>[2024] ULTRA: Exploring Team Recommendations in Two Geographies Using Open Data in Response to Call
                  for
                  Proposals.
                  <br><i>ACM India Joint International Conference on Data Science and Management of Data
                    (CODS-COMAD-2024)</i><br>
                  <a href="https://dl.acm.org/doi/10.1145/3632410.3632503" target="_blank"><b>[Paper]</b></a>
                  <a href="./bib/ultra-cods.bib" target="_blank" type="text/plain"><b>[BibTex]</b></a>
                  <br><br>
                </li>
                <li>[2022] ULTRA: A Data-driven Approach for Recommending Team Formation in Response to Proposal Calls.
                  <br><i>IEEE ICDM Workshop on AI for Nudging and Personalization (WAIN)</i><br>
                  <a href="https://arxiv.org/abs/2201.05646" target="_blank"><b>[Paper]</b></a>
                  <a href="./bib/ultra-icdm.bib" target="_blank" type="text/plain"><b>[BibTex]</b></a>
                  <br>
                </li>
                <br>

                <center>
                  <div>
                    <figure class="imageLeft">
                      <img class="top" src="images/ultra_teaming_setup.png" width="330" height="250" />
                      <figcaption> Figure 1: Teaming setup of ULTRA.</figcaption>
                    </figure>
                    <figure class="imageRight">
                      <img class="average" src="images/ultra_system_architecture.png" width="330" height="250" />
                      <figcaption> Figure 2: System architecture of ULTRA.</figcaption>
                    </figure>
                  </div>
                </center>

              </ul>

              <h3><span style="background-color: aqua;"><b>Additional Tools</b></span></h3>
              <i><b>Collaborators over the years: </b>
                <a target="_blank" href="https://aniketgupta01.wordpress.com/">Aniket Gupta</a>,
                <a target="_blank" href="https://sites.google.com/site/biplavsrivastava/home?authuser=0">Biplav
                  Srivastava</a>,
                Karan Aggarwal, <a target="_blank" href="https://www.linkedin.com/in/sai-teja-paladi-52a062140/">Sai
                  Teja
                  Paladi</a>
              </i><br>

              <p align="justify">Here, we describe some of the important tools that we have developed as part of the <a
                  href="https://ai4society.github.io/teaming/#:~:text=can%20be%20enlarged).-,Team%20Formation,-Technical%20Lead%3A">ULTRA</a>
                effort. They started out as useful features that we then made into stand-alone capabilities recognizing
                their potentia for wider usage:</p>
              <ul style="padding-left:2.5%;width:100%;vertical-align:middle">
                <li>
                  <p align="justify"><img id="myImg3" src="./images/kite.png"
                      alt="KITE - An Unsupervised, Effective and Inclusive Approach for Textual Content Exploration."
                      style="width:100%;max-width:100px;height:48px;"><span style="color:violet">KITE (right)</span> is
                    an
                    unsupervised system for exploring textual
                    data which can generate insights from a general as well as a domain-dependent perspective consisting
                    of
                    holistic views, entity-centric view, events view, domain-specific interpretation using industry
                    taxonomies and a detailed full-text view transparently connecting the document to insight elements.
                  </p>

                  <script>
                    setupModal("myImg3", "myModal", "img01", "caption", "close");
                  </script>
                </li>
                <li>
                  <p align="justify">We also developed a <span style="color:violet"><i>text-to-classification
                        mapper</i></span>, a tool that takes the input
                    as a text and matching threshold as a number and returns the <a
                      href="https://cran.r-project.org/web/classifications/ACM.html" target="_blank">ACM</a> or <a
                      href="https://cran.r-project.org/web/ classifications/JEL.html" target="_blank">JEL</a>
                    classification
                    codes and description based on the input text.</p>
                </li>
              </ul>

              <p><i><b>Representative Publications</b></i></p>
              <ul style="padding-left:2.5%;width:100%;vertical-align:middle">
                <li>[2022] KITE - An Unsupervised, Effective and Inclusive Approach for Textual Content Exploration.<br>
                  <a href="http://casy.cse.sc.edu/kite/" target="_blank"><b>[Tool Website]</b></a>
                  <a href="https://clipchamp.com/watch/oPT2b3oHOAD" target="_blank"><b>[Demo Video]</b></a>
                  <a href="https://www.researchgate.net/profile/Biplav-Srivastava/publication/363608853_KITE_-_An_Unsupervised_Effective_and_Inclusive_Approach_for_Textual_Content_Exploration/links/6324a33a071ea12e363a790e/KITE-An-Unsupervised-Effective-and-Inclusive-Approach-for-Textual-Content-Exploration.pdf"
                    target="_blank"><b>[Paper]</b></a>
                  <a href="https://github.com/BunnyTeja/Text-Visualization" target="_blank"><b>[GitHub]</b></a>
                  <a href="./bib/kite.bib" target="_blank" type="text/plain"><b>[BibTex]</b></a>
                  <br><br>
                  <center>
                    <div style="position:relative;width:fit-content;height:fit-content;">
                      <a style="position:absolute;top:20px;right:1rem;opacity:0.8;"
                        href="https://clipchamp.com/watch/oPT2b3oHOAD?utm_source=embed&utm_medium=embed&utm_campaign=watch">
                        <img loading="lazy" style="height:22px;" src="https://clipchamp.com/e.svg"
                          alt="Made with Clipchamp" />
                      </a>
                      <iframe allow="autoplay;" allowfullscreen style="border:none"
                        src="https://clipchamp.com/watch/oPT2b3oHOAD/embed" width="560" height="315"></iframe>
                    </div>
                  </center>

                </li>
                <br>
                <li>[2022] A Text-to-Classification Mapper (Using ACM/JEL Subject Ontology Codes).<br>
                  <a href="http://casy.cse.sc.edu/mapper/" target="_blank"><b>[Tool Website]</b></a>
                  <br>
                  <center><img src="./images/ultra_mapper.png" width="560" height="315"><br>
                    <figcaption>Figure 3: A demo of text-to-classification mapper.</figcaption>
                  </center>
                </li>
              </ul>
            </div>
          </details>

          <hr>

          <!--Meal reco-->
          <details>
            <summary><b>Meal Recommendation</b></summary>
            <div class="content">
              <p style="text-align: justify;">
                <i><b>Team: </b><a target="_blank"
                    href="https://sites.google.com/site/biplavsrivastava/home?authuser=0">Biplav Srivastava</a>, <a
                    target="_blank" href="https://www.linkedin.com/in/likitha9/">Siva Likitha Valluru</a>, <a
                    target="_blank"
                    href="https://sc.edu/study/colleges_schools/engineering_and_computing/faculty-staff/michaelhuhns.php">Michael
                    Huhns</a>, <a target="_blank" href="https://personal.utdallas.edu/~sriraam.natarajan/">Sriraam
                    Natarajan</a>, <a target="_blank" href="https://kausik-l.github.io/">Kausik Lakkaraju</a>, <a target="_blank" href="https://vishalpallagani.github.io/">Vishal Pallagani</a></i>
                <br>
              </p>
              <p>
                We extend the problem of group recommendation to another use case: meal recommendation. Food is a crucial source for a person’s sustenance, health, and happiness. As a result, a person will benefit from affordable experts (e.g., dieticians) and decision-support technologies (e.g., Artificial Intelligence recommenders) that could help them select meals that they like and are nutritious. This is especially pertinent when the person begins to face a life-long health condition (e.g., diabetes) and has to consider a variety of foods that constitute one or more meals in a day. However, in the absence of a timely, continual, and cost-effective help option to select meals, the person is often unwillingly forced to make hard meal choices, that are often fixed and repeated, between nutrition and taste. It is common to see a person choose healthy food quite late when they have already become a late-stage patient (e.g., diabetes), and the new forced meal plans adversely impact their mental health and happiness. 
                <br><br>
              </p>

              <!-- The Modal -->
              <div id="myModal" class="modal">
                <span class="close">&times;</span>
                <img class="modal-content" id="img01">
                <div id="caption"></div>
              </div>

              <script>
                // Call the function with your specific IDs and class
                setupModal("myImg", "myModal", "img01", "caption", "close");
              </script>
            </div>
          </details>

            </li>
            <br>
            <li>[2022] A Text-to-Classification Mapper (Using ACM/JEL Subject Ontology Codes).<br>
              <a href="http://casy.cse.sc.edu/mapper/" target="_blank"><b>[Tool Website]</b></a>
              <br>
              <center><img src="./images/ultra_mapper.png" width="560" height="315"><br>
                <figcaption>Figure 5: A demo of text-to-classification mapper.</figcaption>
              </center>
            </li>
          </ul>
        </td>

      </tr>

      </tr>

      <hr>

      <tr style="padding:0px">
        <td style="padding-left:2.5%;width:63%;vertical-align:middle">
          <hr style="width: 100%; float: left;">
        </td>
      </tr>
    </tbody>
  </table>
</body>

</html>